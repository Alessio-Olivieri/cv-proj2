{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5786b438-0515-4a0c-880e-1c70127eab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.12/site-packages/deeplake/__init__.py:323: UserWarning: Global variable 'ds_test' of type <class 'deeplake._deeplake.DatasetView'> may cause issues when using fork-based multiprocessing. Consider avoiding global variables of this type, or pass to subprocess as an agrument or by manual pickling.\n",
      "  warnings.warn(\n",
      "/home/user/.local/lib/python3.12/site-packages/deeplake/__init__.py:323: UserWarning: Global variable '_51' of type <class 'deeplake._deeplake.RowView'> may cause issues when using fork-based multiprocessing. Consider avoiding global variables of this type, or pass to subprocess as an agrument or by manual pickling.\n",
      "  warnings.warn(\n",
      "/home/user/.local/lib/python3.12/site-packages/deeplake/__init__.py:323: UserWarning: Global variable '_54' of type <class 'deeplake._deeplake.ColumnView'> may cause issues when using fork-based multiprocessing. Consider avoiding global variables of this type, or pass to subprocess as an agrument or by manual pickling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pillow -q\n",
    "!pip install datasets -q\n",
    "!pip install torch -q\n",
    "!pip install torchvision -q\n",
    "!pip install matplotlib -q\n",
    "!pip install datasets -q\n",
    "!pip install torchmetrics -q\n",
    "!pip install timm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08a43959-192b-4e10-8e24-08a75f47936d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 21:12:38.149422: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747689158.622958    1125 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747689158.713010    1125 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-19 21:12:39.519200: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import PIL\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import os\n",
    "import timm\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "import pickle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f7006-82b5-420e-939c-1f3adfc71b4a",
   "metadata": {},
   "source": [
    "# Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db987980-afaf-41b4-8416-376ad6c9fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "NUM_CLASSES = 200\n",
    "BATCH_SIZE = 64  \n",
    "NUM_EPOCHS = 10  \n",
    "LEARNING_RATE = 1e-4  \n",
    "WEIGHT_DECAY = 0.01  \n",
    "IMAGE_SIZE = 384\n",
    "LOG_INTERVAL = 100 \n",
    "DATA_DIR = \"data/\"\n",
    "MODEL_DIRS = DATA_DIR+\"models/\"\n",
    "BASE_MODEL = MODEL_DIRS+\"interpolated_vit_tiny_imagenet.pth\"\n",
    "TRAIN_DATA = DATA_DIR+\"train.pkl\"\n",
    "VALID_DATA = DATA_DIR+\"valid.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39183afb-2c1e-4125-9ca6-7cf6a07d9df5",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2843a9a-842c-41ef-ae59-510d9ace8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchDatasetWrapper(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.transform=transform\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.hf_dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.hf_dataset[idx]\n",
    "        image = example['image']\n",
    "        if self.transform:\n",
    "            image =  self.transform(image)\n",
    "        return image, example['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca34d5ba-0bc2-4172-9981-fa82259e9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_super_tiny(dataset, split, q=10, p=0, step=500, classes=200):\n",
    "    from datasets import Dataset\n",
    "    images_per_class = {\"validation\":50,\n",
    "                       \"test\":50,\n",
    "                       \"train\":500\n",
    "                       }\n",
    "    dataset_length = images_per_class[split]*classes\n",
    "    t = [dataset[p+i:i+q] for i in range(0, dataset_length-q, step)]\n",
    "    all_images = [image for image_class_dict in t for image in image_class_dict[\"image\"]]\n",
    "    all_labels = [image for image_class_dict in t for image in image_class_dict[\"label\"]]\n",
    "    return Dataset.from_dict({\"image\":all_images, \"label\":all_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7660c735-45a1-4af2-a526-a9191a5a8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_patches(image_unfolded):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from torchvision.utils import make_grid\n",
    "    visualize = v2.Compose([v2.ToPILImage(), v2.Resize((100,100))])\n",
    "    if len(image_unfolded.shape) == 5:\n",
    "        image_unfolded = image_unfolded[None,:,:,:,:,:]\n",
    "    for i in range(image_unfolded.shape[0]):\n",
    "        n_channels, n_patches_h, n_patches_w, h, w = image_unfolded.shape[1:]\n",
    "        patches = image_unfolded[i].permute(1, 2, 0, 3, 4).reshape(-1, n_channels, h, w)\n",
    "        for patch in patches:\n",
    "            visualize(patch).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e67dcbb-3721-493b-9a46-67a1b9639ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = v2.Compose([v2.ToPILImage(), v2.Resize((100,100), antialias=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07531a1-5f50-4b08-aebb-a11da59bee09",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e5d62-b38e-40dd-8e13-59ede06b61a5",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59211dfa-bfcc-40c4-b222-c988aff462f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_dataset = pickle.load(open(TRAIN_DATA,\"rb\"))\n",
    "    valid_dataset = pickle.load(open(VALID_DATA,\"rb\"))\n",
    "except:\n",
    "    train_dataset = load_dataset('Maysee/tiny-imagenet', split='train')\n",
    "    valid_dataset = load_dataset('Maysee/tiny-imagenet', split='valid')\n",
    "    pickle.dump(train_dataset, open(TRAIN_DATA,\"wb\"))\n",
    "    pickle.dump(valid_dataset, open(VALID_DATA,\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e9a41-724b-4dbd-a8a3-4e77ef4dbc55",
   "metadata": {},
   "source": [
    "#### Data Augmentation and Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc0e50f-82e1-47d0-be7b-42570b4e2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = v2.Compose([\n",
    "    v2.Lambda(lambda x: x.convert('RGB')),  # some images are in grayscale\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandAugment(),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    v2.RandomErasing(p=0.25),\n",
    "\n",
    "])\n",
    "\n",
    "transform_valid = v2.Compose([\n",
    "    v2.Lambda(lambda x: x.convert('RGB')),  # some images are in grayscale\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbcc759a-bc88-4cd7-850a-4d522575fe9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 2.0777,  2.1290,  2.1462,  ...,  2.2318,  2.2318,  2.2318],\n",
       "           [ 2.1633,  2.1462,  2.1633,  ...,  2.2318,  2.2318,  2.2318],\n",
       "           [ 2.1975,  2.1975,  2.1633,  ...,  2.2147,  2.2147,  2.2147],\n",
       "           ...,\n",
       "           [ 1.2728,  1.9578,  2.2318,  ...,  1.6838,  1.6667,  1.5982],\n",
       "           [ 2.0434,  2.0777,  1.8037,  ...,  2.1462,  2.1119,  1.9920],\n",
       "           [ 2.0092,  1.9407,  2.0263,  ...,  2.2318,  2.2318,  2.1975]],\n",
       " \n",
       "          [[ 2.4111,  2.4111,  2.4286,  ...,  2.4111,  2.4111,  2.4111],\n",
       "           [ 2.4286,  2.4286,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
       "           [ 2.4286,  2.4286,  2.4111,  ...,  2.3936,  2.3936,  2.3936],\n",
       "           ...,\n",
       "           [ 1.4482,  2.1485,  2.4286,  ...,  1.8508,  1.8333,  1.7633],\n",
       "           [ 2.4286,  2.4286,  2.1835,  ...,  2.3235,  2.2885,  2.2185],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4111,  2.4111,  2.4286]],\n",
       " \n",
       "          [[ 2.5703,  2.5877,  2.6051,  ...,  2.6226,  2.6226,  2.6226],\n",
       "           [ 2.6226,  2.6051,  2.6051,  ...,  2.6226,  2.6226,  2.6226],\n",
       "           [ 2.6400,  2.6400,  2.6051,  ...,  2.6051,  2.6051,  2.6051],\n",
       "           ...,\n",
       "           [ 1.6988,  2.3960,  2.6400,  ...,  2.2391,  2.2217,  2.1520],\n",
       "           [ 2.6400,  2.6400,  2.3263,  ...,  2.6400,  2.6400,  2.5877],\n",
       "           [ 2.6400,  2.6051,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
       " \n",
       " \n",
       "         [[[ 0.6906,  0.6734,  0.6392,  ...,  0.5022,  0.5193,  0.5878],\n",
       "           [ 0.6734,  0.6563,  0.6392,  ...,  0.5536,  0.6221,  0.6906],\n",
       "           [ 0.8618,  0.8447,  0.8104,  ...,  0.4851,  0.5022,  0.5193],\n",
       "           ...,\n",
       "           [ 0.3309,  0.3652,  0.3994,  ...,  0.5022,  0.3138,  0.1083],\n",
       "           [ 0.3481,  0.3823,  0.4166,  ...,  0.6049,  0.4337,  0.1768],\n",
       "           [ 0.2624,  0.2967,  0.3652,  ...,  0.6734,  0.5193,  0.2282]],\n",
       " \n",
       "          [[ 1.0630,  1.0455,  1.0105,  ...,  0.8354,  0.8529,  0.9230],\n",
       "           [ 1.0455,  1.0280,  1.0105,  ...,  0.8880,  0.9580,  1.0280],\n",
       "           [ 1.2381,  1.2206,  1.1856,  ...,  0.8179,  0.8354,  0.8529],\n",
       "           ...,\n",
       "           [ 0.6779,  0.7129,  0.7479,  ...,  0.8704,  0.6954,  0.4853],\n",
       "           [ 0.6954,  0.7304,  0.7654,  ...,  0.9755,  0.8004,  0.5378],\n",
       "           [ 0.6078,  0.6429,  0.7129,  ...,  1.0455,  0.8880,  0.6429]],\n",
       " \n",
       "          [[ 1.1237,  1.1062,  1.0714,  ...,  0.7576,  0.7751,  0.8448],\n",
       "           [ 1.1062,  1.0888,  1.0714,  ...,  0.8099,  0.8797,  0.9494],\n",
       "           [ 1.2980,  1.2805,  1.2457,  ...,  0.7402,  0.7576,  0.7751],\n",
       "           ...,\n",
       "           [ 0.5136,  0.5485,  0.6182,  ...,  0.9145,  0.6879,  0.4788],\n",
       "           [ 0.5311,  0.5659,  0.6356,  ...,  1.0191,  0.8448,  0.5834],\n",
       "           [ 0.4439,  0.4788,  0.5834,  ...,  1.1062,  0.9319,  0.6705]]],\n",
       " \n",
       " \n",
       "         [[[-1.7240, -1.7412, -1.7754,  ..., -0.8507, -1.1418, -1.6042],\n",
       "           [-1.6727, -1.6727, -1.6898,  ..., -1.1075, -1.3302, -1.3644],\n",
       "           [-1.6555, -1.6555, -1.6384,  ..., -1.2617, -1.3987, -1.2959],\n",
       "           ...,\n",
       "           [-1.3815, -1.4500, -1.5014,  ..., -1.3130, -1.2617, -1.2617],\n",
       "           [-1.3815, -1.3987, -1.4500,  ..., -1.3644, -1.3302, -1.2959],\n",
       "           [-1.1589, -1.2103, -1.3130,  ..., -1.5014, -1.5185, -1.4843]],\n",
       " \n",
       "          [[-1.6681, -1.6856, -1.7206,  ..., -0.7577, -1.0903, -1.5630],\n",
       "           [-1.6155, -1.6155, -1.6331,  ..., -1.0203, -1.2479, -1.3179],\n",
       "           [-1.5980, -1.5980, -1.5805,  ..., -1.1779, -1.3179, -1.2129],\n",
       "           ...,\n",
       "           [-0.9678, -1.0378, -1.0903,  ..., -0.8277, -0.7752, -0.7752],\n",
       "           [-0.9678, -0.9853, -1.0028,  ..., -0.8803, -0.8452, -0.8102],\n",
       "           [-0.7402, -0.7927, -0.8627,  ..., -1.0203, -1.0378, -1.0028]],\n",
       " \n",
       "          [[-1.0550, -1.0724, -1.1247,  ..., -0.2184, -0.5321, -1.0027],\n",
       "           [-1.0027, -1.0027, -1.0376,  ..., -0.4798, -0.7064, -0.7587],\n",
       "           [-0.9853, -0.9853, -0.9853,  ..., -0.6367, -0.7761, -0.6715],\n",
       "           ...,\n",
       "           [-0.0790, -0.1487, -0.2010,  ...,  0.0431,  0.0953,  0.0953],\n",
       "           [-0.0790, -0.0964, -0.1312,  ..., -0.0092,  0.0256,  0.0605],\n",
       "           [ 0.1476,  0.0953,  0.0082,  ..., -0.1487, -0.1661, -0.1312]]]]),\n",
       " tensor([0, 0, 0])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    TorchDatasetWrapper(train_dataset, transform_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,  \n",
    "    pin_memory=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    TorchDatasetWrapper(valid_dataset, transform_valid),\n",
    "    batch_size=3,\n",
    "    shuffle=False,\n",
    "    num_workers=2,  \n",
    "    pin_memory=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True\n",
    ")\n",
    "next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14d53f68-ba90-44ff-bdfa-81e62daf8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixup and CutMix\n",
    "mixup_fn = timm.data.Mixup(\n",
    "    mixup_alpha=0.8,\n",
    "    cutmix_alpha=1.0,\n",
    "    cutmix_minmax=None,\n",
    "    prob=0.5,  # Reduced probability to allow some original images\n",
    "    switch_prob=0.5,\n",
    "    mode='batch',\n",
    "    label_smoothing=0.1,\n",
    "    num_classes=NUM_CLASSES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849005a-fdca-4391-8bd5-a6ac7a2f6cb1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3beed236-132c-426f-82ae-3a4e79352170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('vit_base_patch16_384', pretrained=True, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3e66be-fe31-45e8-9a10-c013516fdb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:309: UserWarning: Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\n",
      "  warnings.warn(\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\")\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patch_kernels = model.patch_embed.proj.weight\n",
    "interpooled_patch_embedding = torch.nn.functional.interpolate(patch_kernels, size=(8,8), mode=\"bicubic\")\n",
    "visualize(interpooled_patch_embedding[59]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d80cc7b-1026-4b3f-8770-ab62d1bf1951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 577, 768])\n",
      "torch.Size([1, 64, 768])\n"
     ]
    }
   ],
   "source": [
    "pos_embed = model.pos_embed\n",
    "print(pos_embed.shape)\n",
    "pos_embed = pos_embed.reshape(577, 768)\n",
    "cls_pos_embedding, pos_embed = torch.split(pos_embed, [1, 576])\n",
    "pos_embed = pos_embed.reshape(24, 24, 768).permute(2, 0, 1)\n",
    "pos_embed.shape\n",
    "pos_embed = torch.nn.functional.interpolate(pos_embed.unsqueeze(0), size=(8, 8), mode=\"bicubic\")\n",
    "pos_embed = pos_embed.reshape(1, 768, 64).permute(0, 2, 1)\n",
    "print(pos_embed.shape)\n",
    "pos_embed = torch.cat([pos_embed, cls_pos_embedding.unsqueeze(0)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f757151f-6ba4-4b63-af2d-f82037bef2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pos_embed = torch.nn.Parameter(pos_embed)\n",
    "model.patch_embed.proj = torch.nn.Conv2d(3, 768, kernel_size=(8, 8), stride=(8, 8))\n",
    "model.patch_embed.proj.weight = torch.nn.Parameter(interpooled_patch_embedding)\n",
    "model.img_size = 64\n",
    "model.patch_embed.img_size = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddaf3af2-3c2e-4094-93bc-90c259064351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63911c64-7406-42ea-b806-34f0f1f5dc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5809fabe-a88a-429c-9279-aa1121ee2247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(BASE_MODEL, weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb7102ac-83df-48b6-b95b-169a7eea1854",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbaad8c-cef0-402f-a0b8-fab96f0bf39f",
   "metadata": {},
   "source": [
    "Evaluation of model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3758d38-564e-4f20-aeb4-3e74d717ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 100%|███████████████████████████████████████████████████████████████████████████████| 157/157 [00:15<00:00, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking batch size 1\n",
      "Benchmarking batch size 2\n",
      "Benchmarking batch size 4\n",
      "Benchmarking batch size 8\n",
      "Benchmarking batch size 16\n",
      "Benchmarking batch size 32\n",
      "Benchmarking batch size 64\n",
      "Benchmarking CPU\n",
      "Benchmarking batch size 1\n",
      "Benchmarking batch size 2\n",
      "Benchmarking batch size 4\n",
      "Benchmarking batch size 8\n",
      "Benchmarking batch size 16\n",
      "Benchmarking batch size 32\n",
      "Benchmarking batch size 64\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def benchmark_model(model, device, gpu=True, cpu=False, WARMUPS=10, batch_sizes=[1,2,4,8,16,32,64], n_iters=[50,25,10,10,10,10,10], acc=True, cpu_acc=False):\n",
    "    def test_accuracy(model, device, WARMUPS=10, batch_sizes=[1,2,4,8,16,32,64], n_iters=[50,25,10,10,10,10,10], acc=True, cpu_acc=False):\n",
    "        if not cpu_acc and device.type == \"cpu\":\n",
    "            raise AssertionError(\"Set cpu_acc=True if you want to check accuracy with cpu, otherwise set acc=False to skip accuracy benchmark\")\n",
    "        model.to(device)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            TorchDatasetWrapper(valid_dataset, transform_valid),\n",
    "            batch_size=max(batch_sizes),\n",
    "            shuffle=False,\n",
    "            num_workers=2,  \n",
    "            pin_memory=True,\n",
    "            prefetch_factor=4,\n",
    "            persistent_workers=True\n",
    "        )\n",
    "        test_loader_tqdm = tqdm(test_loader, desc=f\"Testing Accuracy\")\n",
    "        total=0\n",
    "        correct=0\n",
    "        for images, labels in test_loader_tqdm:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            batch_correct = predicted.eq(labels).sum().item()\n",
    "            correct += batch_correct\n",
    "            total += len(labels)\n",
    "        return correct/total\n",
    "\n",
    "    def test_gpu_speed(model, device, WARMUPS=10, batch_sizes=[1,2,4,8,16,32,64], n_iters=[50,25,10,10,10,10,10], acc=True, cpu_acc=False):\n",
    "        print(\"Benchmarking GPU\")\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        results = []\n",
    "        model.to(device)\n",
    "        for batch_size,  n_iter in zip(batch_sizes, n_iters):\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                TorchDatasetWrapper(valid_dataset, transform_valid),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=2,  \n",
    "                pin_memory=True,\n",
    "                prefetch_factor=4,\n",
    "                persistent_workers=True\n",
    "            )\n",
    "            \n",
    "            images, labels = next(iter(test_loader))\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            for _ in range(WARMUPS):\n",
    "                _ = model(images)\n",
    "            print(f\"Benchmarking batch size {batch_size}\")\n",
    "            torch.cuda.synchronize()\n",
    "            start_event.record()\n",
    "            with torch.no_grad():\n",
    "                for _ in range(n_iter):\n",
    "                    _ = model(images)\n",
    "            end_event.record()\n",
    "            torch.cuda.synchronize() \n",
    "            elapsed = start_event.elapsed_time(end_event) / 100\n",
    "            avg_time_per_batch = elapsed / n_iter * 1000  # ms per batch\n",
    "            avg_time_per_image = avg_time_per_batch / batch_size   # ms per image\n",
    "            throughput = 1000 / avg_time_per_image         # images/second\n",
    "            batch_result = {\"bs\":batch_size, \"mode\":\"gpu\",}\n",
    "            batch_result[\"values\"] = {\n",
    "                \"time_per_batch_ms\": avg_time_per_batch,\n",
    "                \"time_per_image_ms\": avg_time_per_image,\n",
    "                \"throughput_imgs/s\": throughput\n",
    "            }\n",
    "            results.append(batch_result)\n",
    "        return results\n",
    "            \n",
    "    def test_cpu_speed(model, device, WARMUPS=10, batch_sizes=[1,2,4,8,16,32,64], n_iters=[64,32,16,8,4,2,1], acc=True, cpu_acc=False):\n",
    "        print(\"Benchmarking CPU\")\n",
    "        results = []\n",
    "        model = model.to(torch.device(\"cpu\"))\n",
    "        for batch_size,  n_iter in zip(batch_sizes, n_iters):\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                TorchDatasetWrapper(valid_dataset, transform_valid),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=2,  \n",
    "                pin_memory=False,\n",
    "                persistent_workers=False\n",
    "            )\n",
    "            images, labels = next(iter(test_loader))\n",
    "            for _ in range(WARMUPS):\n",
    "                _ = model(images)\n",
    "            print(f\"Benchmarking batch size {batch_size}\")\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                for _ in range(n_iter):\n",
    "                    _ = model(images)\n",
    "            elapsed = time.time() - start_time\n",
    "            avg_time_per_batch = elapsed / n_iter * 1000  # ms per batch\n",
    "            avg_time_per_image = avg_time_per_batch / batch_size   # ms per image\n",
    "            throughput = 1000 / avg_time_per_image         # images/second\n",
    "            batch_result = {\"bs\":batch_size, \"mode\":\"cpu\",}\n",
    "            batch_result[\"values\"] = {\n",
    "                \"time_per_batch_ms\": avg_time_per_batch,\n",
    "                \"time_per_image_ms\": avg_time_per_image,\n",
    "                \"throughput_imgs/s\": throughput\n",
    "            }\n",
    "            results.append(batch_result)\n",
    "        return results\n",
    "\n",
    "        def process_results(results_gpu, results_cpu):\n",
    "            results = []\n",
    "            if results_gpu and results_cpu: \n",
    "                results_zipped = zip(results_gpu, results_cpu)\n",
    "            elif results_gpu:\n",
    "                results_zipped = zip(results_gpu, [[]]*len(results_gpu))\n",
    "            elif results_cpu:\n",
    "                results_zipped = zip(results_cpu, [[]]*len(results_gpu))\n",
    "        \n",
    "            for result_gpu, result_cpu in results_zipped:\n",
    "                dic = []\n",
    "                if result_gpu: \n",
    "                    batch_size = result_gpu.pop(\"bs\")\n",
    "                    dic.append(result_gpu)\n",
    "                if result_cpu: \n",
    "                    batch_size = result_cpu.pop(\"bs\")\n",
    "                    dic.append(result_cpu)\n",
    "                results.append({\"batch_size\":batch_size,\n",
    "                               \"value\":dic\n",
    "                               })\n",
    "            return results\n",
    "        \n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    if acc:\n",
    "        accuracy = test_accuracy(model, device, WARMUPS, batch_sizes, n_iters, acc, cpu_acc)\n",
    "    if gpu:\n",
    "        results_gpu = test_gpu_speed(model, device, WARMUPS, batch_sizes, n_iters, acc, cpu_acc)\n",
    "    if cpu:\n",
    "        results_cpu = test_cpu_speed(model, device, WARMUPS, batch_sizes, [64,32,16,8,4,2,1], acc, cpu_acc)\n",
    "    return process_results(results_gpu, results_cpu), accuracy\n",
    "\n",
    "benchmark, accuracy = benchmark_model(model, device, gpu=True, cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802be35-ffb2-4498-9bbe-286d31f055ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
