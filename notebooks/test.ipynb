{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append('../src')\n",
    "from modules import (\n",
    "                    paths,\n",
    "                    dataset,\n",
    "                    model,\n",
    "                    utils,\n",
    "                    acdc\n",
    "                    )\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = True\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laoding toy datasets\n",
      "Loading dataset from /home/lexyo/Dev/cv-proj2/notebooks/../data/train.pkl\n",
      "Loading dataset from /home/lexyo/Dev/cv-proj2/notebooks/../data/valid.pkl\n",
      "train:\n",
      "Dataset({\n",
      "    features: ['image', 'label'],\n",
      "    num_rows: 400\n",
      "})\n",
      "validation:\n",
      "Dataset({\n",
      "    features: ['image', 'label'],\n",
      "    num_rows: 400\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(dataset)\n",
    "if toy == True:\n",
    "    print(\"laoding toy datasets\")\n",
    "    train_dataset = dataset.load(\"train\", tiny=True, stop=2)\n",
    "    val_dataset = dataset.load(\"valid\", tiny=True, stop=2)\n",
    "\n",
    "else:\n",
    "    print(\"loading full dataet\")\n",
    "    train_dataset = dataset.load(\"train\", stop=2)\n",
    "    val_dataset = dataset.load(\"valid\", stop=2)\n",
    "print(\"train:\\n\"+str(train_dataset))\n",
    "print(\"validation:\\n\"+str(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = v2.Compose([\n",
    "    v2.Lambda(lambda x: x.convert('RGB')),  # some images are in grayscale\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandAugment(),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    v2.RandomErasing(p=0.25),\n",
    "\n",
    "])\n",
    "\n",
    "transform_valid = v2.Compose([\n",
    "    v2.Lambda(lambda x: x.convert('RGB')),  # some images are in grayscale\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset.TorchDatasetWrapper(train_dataset, transform_train),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,  \n",
    "    pin_memory=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset.TorchDatasetWrapper(val_dataset, transform_valid),\n",
    "    batch_size=3,\n",
    "    shuffle=False,\n",
    "    num_workers=2,  \n",
    "    pin_memory=True,\n",
    "    prefetch_factor=4,\n",
    "    persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lexyo/Dev/cv-proj2/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules.model\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model)\n",
    "config = {\n",
    "    \"patch_size\": 8,           # Kept small for fine-grained patches\n",
    "    \"hidden_size\": 64,          # Increased from 48 (better representation)\n",
    "    \"num_hidden_layers\": 6,     # Deeper for pruning flexibility\n",
    "    \"num_attention_heads\": 8,   # More heads (head_dim = 64/8 = 8)\n",
    "    \"intermediate_size\": 4 * 64,# Standard FFN scaling\n",
    "    \"hidden_dropout_prob\": 0.1, # Mild dropout for regularization\n",
    "    \"attention_probs_dropout_prob\": 0.1,\n",
    "    \"initializer_range\": 0.02,\n",
    "    \"image_size\": 64,\n",
    "    \"num_classes\": 10,\n",
    "    \"num_channels\": 3,\n",
    "    \"qkv_bias\": True,           # Keep bias for now (can prune later)\n",
    "}\n",
    "# embedding = model.Embeddings(config)\n",
    "# x = embedding(batch[0])\n",
    "# single = model.AttentionHead(1000, 10, 0.1)\n",
    "# single(x)\n",
    "# multi = model.MultiHeadAttention(config)\n",
    "# multi(x, output_attentions = True)\n",
    "# encoder = model.Encoder(config)\n",
    "# encoder(x)\n",
    "# input = torch.ones(config[\"hidden_size\"])\n",
    "# bad_input = torch.ones(config[\"hidden_size\"]) +100000\n",
    "vit = model.ViT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['embedding', 'encoder.blocks.0.mlp.final_output', 'encoder.blocks.0.attention.heads.0.final_output', 'encoder.blocks.0.attention.heads.1.final_output', 'encoder.blocks.0.attention.heads.2.final_output', 'encoder.blocks.0.attention.heads.3.final_output', 'encoder.blocks.0.attention.heads.4.final_output', 'encoder.blocks.0.attention.heads.5.final_output', 'encoder.blocks.0.attention.heads.6.final_output', 'encoder.blocks.0.attention.heads.7.final_output', 'encoder.blocks.1.mlp.final_output', 'encoder.blocks.1.attention.heads.0.final_output', 'encoder.blocks.1.attention.heads.1.final_output', 'encoder.blocks.1.attention.heads.2.final_output', 'encoder.blocks.1.attention.heads.3.final_output', 'encoder.blocks.1.attention.heads.4.final_output', 'encoder.blocks.1.attention.heads.5.final_output', 'encoder.blocks.1.attention.heads.6.final_output', 'encoder.blocks.1.attention.heads.7.final_output', 'encoder.blocks.2.mlp.final_output', 'encoder.blocks.2.attention.heads.0.final_output', 'encoder.blocks.2.attention.heads.1.final_output', 'encoder.blocks.2.attention.heads.2.final_output', 'encoder.blocks.2.attention.heads.3.final_output', 'encoder.blocks.2.attention.heads.4.final_output', 'encoder.blocks.2.attention.heads.5.final_output', 'encoder.blocks.2.attention.heads.6.final_output', 'encoder.blocks.2.attention.heads.7.final_output', 'encoder.blocks.3.mlp.final_output', 'encoder.blocks.3.attention.heads.0.final_output', 'encoder.blocks.3.attention.heads.1.final_output', 'encoder.blocks.3.attention.heads.2.final_output', 'encoder.blocks.3.attention.heads.3.final_output', 'encoder.blocks.3.attention.heads.4.final_output', 'encoder.blocks.3.attention.heads.5.final_output', 'encoder.blocks.3.attention.heads.6.final_output', 'encoder.blocks.3.attention.heads.7.final_output', 'encoder.blocks.4.mlp.final_output', 'encoder.blocks.4.attention.heads.0.final_output', 'encoder.blocks.4.attention.heads.1.final_output', 'encoder.blocks.4.attention.heads.2.final_output', 'encoder.blocks.4.attention.heads.3.final_output', 'encoder.blocks.4.attention.heads.4.final_output', 'encoder.blocks.4.attention.heads.5.final_output', 'encoder.blocks.4.attention.heads.6.final_output', 'encoder.blocks.4.attention.heads.7.final_output', 'encoder.blocks.5.mlp.final_output', 'encoder.blocks.5.attention.heads.0.final_output', 'encoder.blocks.5.attention.heads.1.final_output', 'encoder.blocks.5.attention.heads.2.final_output', 'encoder.blocks.5.attention.heads.3.final_output', 'encoder.blocks.5.attention.heads.4.final_output', 'encoder.blocks.5.attention.heads.5.final_output', 'encoder.blocks.5.attention.heads.6.final_output', 'encoder.blocks.5.attention.heads.7.final_output'])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "computation_graph = utils.ComputationalGraph(vit)\n",
    "print(computation_graph.nodes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1317"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(computation_graph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding.final_output': tensor([[[ 0.0065, -0.0174, -0.0183,  ..., -0.0457, -0.0050,  0.0233],\n",
       "          [ 0.2335, -0.2645,  0.0179,  ..., -0.2675, -0.5039,  0.2646],\n",
       "          [ 0.0192, -0.2172,  0.2180,  ..., -0.1022, -0.3378,  0.2323],\n",
       "          ...,\n",
       "          [-0.0906, -0.2557,  0.4264,  ..., -0.2720, -0.0510,  0.0466],\n",
       "          [ 0.0938, -0.2093,  0.5405,  ..., -0.1086, -0.2870,  0.0099],\n",
       "          [-0.1115,  0.3952,  0.2975,  ...,  0.0880, -0.3537,  0.2548]],\n",
       " \n",
       "         [[ 0.0065, -0.0174, -0.0183,  ..., -0.0457, -0.0050,  0.0233],\n",
       "          [-0.1569,  0.2763, -0.2673,  ...,  0.2274,  0.3379,  0.0398],\n",
       "          [-0.4459,  0.2735, -0.1393,  ...,  0.0847,  0.3884, -0.2525],\n",
       "          ...,\n",
       "          [ 0.3496, -0.3625, -0.1129,  ..., -0.2534, -0.5272,  0.2232],\n",
       "          [ 0.0662, -0.4209,  0.2272,  ...,  0.1860, -0.1374,  0.3052],\n",
       "          [ 0.1646, -0.5048, -0.0607,  ..., -0.1067, -0.3631,  0.0732]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " 'encoder.blocks.0.mlp.final_output': tensor([[[ 0.1119,  0.0579, -0.0588,  ...,  0.0445,  0.1298,  0.0101],\n",
       "          [ 0.1116,  0.0581, -0.0585,  ...,  0.0443,  0.1291,  0.0104],\n",
       "          [ 0.1116,  0.0581, -0.0584,  ...,  0.0444,  0.1293,  0.0102],\n",
       "          ...,\n",
       "          [ 0.1121,  0.0578, -0.0588,  ...,  0.0438,  0.1291,  0.0108],\n",
       "          [ 0.1121,  0.0579, -0.0587,  ...,  0.0441,  0.1292,  0.0105],\n",
       "          [ 0.1116,  0.0578, -0.0579,  ...,  0.0438,  0.1293,  0.0104]],\n",
       " \n",
       "         [[-0.0314,  0.0035,  0.0449,  ..., -0.0338, -0.0048, -0.0218],\n",
       "          [-0.0309,  0.0033,  0.0446,  ..., -0.0344, -0.0042, -0.0213],\n",
       "          [-0.0316,  0.0032,  0.0441,  ..., -0.0340, -0.0060, -0.0222],\n",
       "          ...,\n",
       "          [-0.0339,  0.0040,  0.0464,  ..., -0.0343, -0.0073, -0.0232],\n",
       "          [-0.0332,  0.0042,  0.0453,  ..., -0.0341, -0.0063, -0.0237],\n",
       "          [-0.0335,  0.0039,  0.0452,  ..., -0.0340, -0.0075, -0.0237]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.0.attention.heads.0.final_output': tensor([[[ 0.1146, -0.0176,  0.2021,  ...,  0.0138,  0.0398,  0.0182],\n",
       "          [ 0.1147, -0.0179,  0.2024,  ...,  0.0138,  0.0395,  0.0181],\n",
       "          [ 0.1147, -0.0180,  0.2024,  ...,  0.0138,  0.0395,  0.0181],\n",
       "          ...,\n",
       "          [ 0.1154, -0.0179,  0.2032,  ...,  0.0137,  0.0402,  0.0181],\n",
       "          [ 0.1153, -0.0179,  0.2033,  ...,  0.0140,  0.0404,  0.0180],\n",
       "          [ 0.1149, -0.0187,  0.2026,  ...,  0.0131,  0.0396,  0.0181]],\n",
       " \n",
       "         [[-0.0043, -0.0138, -0.0292,  ...,  0.0020, -0.0307, -0.0298],\n",
       "          [ 0.0009, -0.0139, -0.0222,  ...,  0.0008, -0.0297, -0.0298],\n",
       "          [ 0.0004, -0.0136, -0.0224,  ...,  0.0003, -0.0286, -0.0288],\n",
       "          ...,\n",
       "          [-0.0045, -0.0137, -0.0291,  ...,  0.0021, -0.0317, -0.0309],\n",
       "          [-0.0027, -0.0136, -0.0269,  ...,  0.0018, -0.0305, -0.0301],\n",
       "          [-0.0027, -0.0139, -0.0267,  ...,  0.0014, -0.0300, -0.0303]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.0.attention.heads.1.final_output': tensor([[[ 0.0419,  0.0059,  0.1611,  ..., -0.0800, -0.0394,  0.0836],\n",
       "          [ 0.0414,  0.0054,  0.1611,  ..., -0.0800, -0.0385,  0.0833],\n",
       "          [ 0.0414,  0.0054,  0.1611,  ..., -0.0799, -0.0386,  0.0833],\n",
       "          ...,\n",
       "          [ 0.0415,  0.0055,  0.1610,  ..., -0.0799, -0.0389,  0.0834],\n",
       "          [ 0.0416,  0.0056,  0.1611,  ..., -0.0799, -0.0389,  0.0833],\n",
       "          [ 0.0415,  0.0058,  0.1609,  ..., -0.0799, -0.0392,  0.0836]],\n",
       " \n",
       "         [[ 0.0124,  0.0025, -0.0045,  ...,  0.0161,  0.0018,  0.0027],\n",
       "          [ 0.0122,  0.0023, -0.0036,  ...,  0.0153,  0.0023,  0.0025],\n",
       "          [ 0.0122,  0.0018, -0.0031,  ...,  0.0152,  0.0019,  0.0024],\n",
       "          ...,\n",
       "          [ 0.0117,  0.0027, -0.0047,  ...,  0.0180,  0.0026,  0.0020],\n",
       "          [ 0.0116,  0.0024, -0.0052,  ...,  0.0186,  0.0027,  0.0017],\n",
       "          [ 0.0121,  0.0027, -0.0046,  ...,  0.0175,  0.0025,  0.0021]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.0.attention.heads.2.final_output': tensor([[[ 0.0136,  0.0140, -0.0119,  ..., -0.0225,  0.1138, -0.1587],\n",
       "          [ 0.0140,  0.0135, -0.0122,  ..., -0.0234,  0.1150, -0.1582],\n",
       "          [ 0.0140,  0.0134, -0.0123,  ..., -0.0234,  0.1151, -0.1580],\n",
       "          ...,\n",
       "          [ 0.0141,  0.0131, -0.0123,  ..., -0.0239,  0.1159, -0.1577],\n",
       "          [ 0.0141,  0.0133, -0.0122,  ..., -0.0238,  0.1156, -0.1581],\n",
       "          [ 0.0139,  0.0134, -0.0122,  ..., -0.0234,  0.1152, -0.1580]],\n",
       " \n",
       "         [[ 0.0077,  0.0008, -0.0158,  ...,  0.0070,  0.0027,  0.0270],\n",
       "          [ 0.0073,  0.0004, -0.0164,  ...,  0.0073,  0.0034,  0.0271],\n",
       "          [ 0.0077,  0.0010, -0.0147,  ...,  0.0060,  0.0039,  0.0257],\n",
       "          ...,\n",
       "          [ 0.0085,  0.0005, -0.0159,  ...,  0.0072,  0.0034,  0.0280],\n",
       "          [ 0.0091,  0.0003, -0.0146,  ...,  0.0073,  0.0041,  0.0283],\n",
       "          [ 0.0090,  0.0006, -0.0144,  ...,  0.0067,  0.0037,  0.0281]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.0.attention.heads.3.final_output': tensor([[[ 0.0071, -0.0386, -0.0359,  ...,  0.0297,  0.0286, -0.0085],\n",
       "          [-0.0306, -0.0150, -0.0098,  ..., -0.0380,  0.0131,  0.0186],\n",
       "          [-0.0296, -0.0163, -0.0173,  ..., -0.0332, -0.0004,  0.0302],\n",
       "          ...,\n",
       "          [ 0.0068, -0.0165,  0.0003,  ...,  0.0093, -0.0273,  0.0574],\n",
       "          [-0.0383,  0.0001, -0.0034,  ..., -0.0175, -0.0288,  0.0491],\n",
       "          [-0.0115,  0.0050, -0.0381,  ..., -0.0166, -0.0160,  0.0332]],\n",
       " \n",
       "         [[-0.0062, -0.0371, -0.0408,  ...,  0.0271,  0.0247,  0.0032],\n",
       "          [ 0.0107, -0.0211,  0.0072,  ...,  0.0386, -0.0388,  0.0026],\n",
       "          [ 0.0339,  0.0307,  0.0109,  ...,  0.0310,  0.0038, -0.0413],\n",
       "          ...,\n",
       "          [-0.0274, -0.0170, -0.0005,  ..., -0.0306, -0.0024, -0.0048],\n",
       "          [-0.0516, -0.0146,  0.0195,  ..., -0.0285,  0.0157,  0.0403],\n",
       "          [-0.0543,  0.0037, -0.0091,  ..., -0.0402,  0.0284,  0.0168]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " 'encoder.blocks.1.mlp.final_output': tensor([[[-0.0381, -0.0227, -0.0866,  ..., -0.2193, -0.1391, -0.0647],\n",
       "          [-0.0385, -0.0227, -0.0869,  ..., -0.2188, -0.1391, -0.0644],\n",
       "          [-0.0384, -0.0230, -0.0870,  ..., -0.2190, -0.1392, -0.0646],\n",
       "          ...,\n",
       "          [-0.0384, -0.0226, -0.0868,  ..., -0.2189, -0.1390, -0.0645],\n",
       "          [-0.0383, -0.0228, -0.0868,  ..., -0.2188, -0.1391, -0.0647],\n",
       "          [-0.0381, -0.0232, -0.0869,  ..., -0.2192, -0.1393, -0.0650]],\n",
       " \n",
       "         [[-0.0048,  0.0164,  0.0065,  ...,  0.0277,  0.0111, -0.0030],\n",
       "          [-0.0048,  0.0177,  0.0082,  ...,  0.0291,  0.0117, -0.0024],\n",
       "          [-0.0052,  0.0179,  0.0082,  ...,  0.0294,  0.0122, -0.0034],\n",
       "          ...,\n",
       "          [-0.0049,  0.0180,  0.0081,  ...,  0.0291,  0.0114, -0.0023],\n",
       "          [-0.0044,  0.0172,  0.0075,  ...,  0.0290,  0.0117, -0.0018],\n",
       "          [-0.0047,  0.0173,  0.0077,  ...,  0.0290,  0.0119, -0.0022]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.1.attention.heads.0.final_output': tensor([[[-0.0175,  0.0478, -0.0639,  ..., -0.1241,  0.0727,  0.0484],\n",
       "          [-0.0172,  0.0477, -0.0638,  ..., -0.1245,  0.0730,  0.0488],\n",
       "          [-0.0171,  0.0477, -0.0636,  ..., -0.1246,  0.0731,  0.0490],\n",
       "          ...,\n",
       "          [-0.0171,  0.0477, -0.0637,  ..., -0.1246,  0.0731,  0.0491],\n",
       "          [-0.0173,  0.0477, -0.0639,  ..., -0.1247,  0.0731,  0.0489],\n",
       "          [-0.0173,  0.0477, -0.0639,  ..., -0.1245,  0.0729,  0.0486]],\n",
       " \n",
       "         [[-0.0287, -0.0004, -0.0136,  ...,  0.0085, -0.0030, -0.0267],\n",
       "          [-0.0278, -0.0010, -0.0145,  ...,  0.0082, -0.0028, -0.0264],\n",
       "          [-0.0280, -0.0014, -0.0151,  ...,  0.0095, -0.0047, -0.0268],\n",
       "          ...,\n",
       "          [-0.0280, -0.0005, -0.0144,  ...,  0.0068, -0.0011, -0.0267],\n",
       "          [-0.0277, -0.0006, -0.0145,  ...,  0.0067, -0.0005, -0.0265],\n",
       "          [-0.0276, -0.0009, -0.0146,  ...,  0.0082, -0.0016, -0.0268]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.1.attention.heads.1.final_output': tensor([[[-0.0287,  0.0014,  0.0470,  ...,  0.0925, -0.0601, -0.0944],\n",
       "          [-0.0285,  0.0021,  0.0472,  ...,  0.0923, -0.0598, -0.0950],\n",
       "          [-0.0286,  0.0019,  0.0473,  ...,  0.0925, -0.0601, -0.0946],\n",
       "          ...,\n",
       "          [-0.0285,  0.0017,  0.0472,  ...,  0.0923, -0.0599, -0.0946],\n",
       "          [-0.0284,  0.0021,  0.0471,  ...,  0.0919, -0.0594, -0.0949],\n",
       "          [-0.0285,  0.0021,  0.0471,  ...,  0.0922, -0.0596, -0.0950]],\n",
       " \n",
       "         [[ 0.0026,  0.0284, -0.0121,  ..., -0.0475,  0.0502, -0.0068],\n",
       "          [ 0.0018,  0.0288, -0.0091,  ..., -0.0454,  0.0485, -0.0064],\n",
       "          [ 0.0026,  0.0285, -0.0094,  ..., -0.0456,  0.0491, -0.0062],\n",
       "          ...,\n",
       "          [ 0.0023,  0.0288, -0.0100,  ..., -0.0463,  0.0494, -0.0059],\n",
       "          [ 0.0021,  0.0287, -0.0108,  ..., -0.0467,  0.0496, -0.0068],\n",
       "          [ 0.0026,  0.0285, -0.0111,  ..., -0.0470,  0.0501, -0.0068]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.1.attention.heads.2.final_output': tensor([[[ 0.0505,  0.2013, -0.1464,  ...,  0.0366, -0.0039,  0.1883],\n",
       "          [ 0.0508,  0.2015, -0.1463,  ...,  0.0361, -0.0034,  0.1884],\n",
       "          [ 0.0508,  0.2015, -0.1463,  ...,  0.0362, -0.0035,  0.1884],\n",
       "          ...,\n",
       "          [ 0.0506,  0.2013, -0.1462,  ...,  0.0355, -0.0035,  0.1888],\n",
       "          [ 0.0506,  0.2012, -0.1462,  ...,  0.0352, -0.0034,  0.1887],\n",
       "          [ 0.0506,  0.2011, -0.1462,  ...,  0.0356, -0.0033,  0.1884]],\n",
       " \n",
       "         [[ 0.0167, -0.0251,  0.0094,  ..., -0.0421,  0.0293, -0.0361],\n",
       "          [ 0.0172, -0.0220,  0.0080,  ..., -0.0414,  0.0285, -0.0336],\n",
       "          [ 0.0167, -0.0229,  0.0079,  ..., -0.0423,  0.0287, -0.0344],\n",
       "          ...,\n",
       "          [ 0.0183, -0.0232,  0.0089,  ..., -0.0421,  0.0312, -0.0364],\n",
       "          [ 0.0182, -0.0213,  0.0078,  ..., -0.0421,  0.0305, -0.0343],\n",
       "          [ 0.0179, -0.0229,  0.0085,  ..., -0.0424,  0.0308, -0.0359]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.1.attention.heads.3.final_output': tensor([[[ 0.0226,  0.0224,  0.0229,  ...,  0.0260, -0.0073,  0.0240],\n",
       "          [ 0.0315, -0.0252,  0.0372,  ...,  0.0034, -0.0261, -0.0300],\n",
       "          [ 0.0299, -0.0205,  0.0363,  ..., -0.0042, -0.0373, -0.0463],\n",
       "          ...,\n",
       "          [ 0.0066,  0.0078,  0.0370,  ..., -0.0117, -0.0245, -0.0543],\n",
       "          [ 0.0118, -0.0156,  0.0396,  ..., -0.0104, -0.0102, -0.0364],\n",
       "          [ 0.0031, -0.0040,  0.0334,  ..., -0.0035, -0.0209, -0.0085]],\n",
       " \n",
       "         [[ 0.0146, -0.0172,  0.0161,  ...,  0.0102, -0.0094,  0.0012],\n",
       "          [-0.0086, -0.0111, -0.0319,  ...,  0.0070,  0.0157,  0.0131],\n",
       "          [-0.0233,  0.0095, -0.0585,  ..., -0.0020,  0.0356,  0.0251],\n",
       "          ...,\n",
       "          [ 0.0353, -0.0222,  0.0384,  ..., -0.0029, -0.0188, -0.0388],\n",
       "          [ 0.0193, -0.0327,  0.0199,  ..., -0.0119, -0.0221, -0.0355],\n",
       "          [ 0.0090, -0.0085,  0.0271,  ..., -0.0112, -0.0127, -0.0181]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " 'encoder.blocks.2.mlp.final_output': tensor([[[ 4.9914e-03,  1.6183e-01, -2.4404e-02,  ..., -1.9030e-01,\n",
       "           -1.9189e-01, -1.8043e-02],\n",
       "          [ 5.2088e-03,  1.6166e-01, -2.4720e-02,  ..., -1.8975e-01,\n",
       "           -1.9185e-01, -1.7980e-02],\n",
       "          [ 5.2561e-03,  1.6172e-01, -2.4653e-02,  ..., -1.8969e-01,\n",
       "           -1.9184e-01, -1.8015e-02],\n",
       "          ...,\n",
       "          [ 5.0872e-03,  1.6141e-01, -2.4602e-02,  ..., -1.8972e-01,\n",
       "           -1.9182e-01, -1.8112e-02],\n",
       "          [ 5.2288e-03,  1.6153e-01, -2.4650e-02,  ..., -1.8976e-01,\n",
       "           -1.9176e-01, -1.7969e-02],\n",
       "          [ 5.2586e-03,  1.6154e-01, -2.4586e-02,  ..., -1.8942e-01,\n",
       "           -1.9149e-01, -1.7992e-02]],\n",
       " \n",
       "         [[-8.0779e-03, -1.6745e-02, -4.1381e-03,  ..., -1.2616e-03,\n",
       "            5.0501e-02,  2.5762e-02],\n",
       "          [-8.7948e-03, -1.6786e-02, -4.1460e-03,  ..., -2.8696e-03,\n",
       "            4.8631e-02,  2.5650e-02],\n",
       "          [-8.5072e-03, -1.6396e-02, -3.8280e-03,  ..., -2.1292e-03,\n",
       "            4.8373e-02,  2.5393e-02],\n",
       "          ...,\n",
       "          [-7.5961e-03, -1.6939e-02, -4.4789e-03,  ..., -1.0430e-03,\n",
       "            5.2149e-02,  2.6416e-02],\n",
       "          [-8.1248e-03, -1.7322e-02, -4.6167e-03,  ..., -9.7114e-04,\n",
       "            5.2040e-02,  2.6593e-02],\n",
       "          [-7.4304e-03, -1.6193e-02, -4.2874e-03,  ..., -1.7829e-04,\n",
       "            5.1657e-02,  2.6070e-02]]], grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.2.attention.heads.0.final_output': tensor([[[ 0.1075, -0.0705,  0.1040,  ...,  0.2184,  0.1163, -0.1089],\n",
       "          [ 0.1078, -0.0702,  0.1042,  ...,  0.2183,  0.1163, -0.1095],\n",
       "          [ 0.1075, -0.0702,  0.1043,  ...,  0.2185,  0.1164, -0.1096],\n",
       "          ...,\n",
       "          [ 0.1074, -0.0703,  0.1045,  ...,  0.2185,  0.1165, -0.1091],\n",
       "          [ 0.1080, -0.0701,  0.1046,  ...,  0.2183,  0.1165, -0.1088],\n",
       "          [ 0.1076, -0.0702,  0.1045,  ...,  0.2185,  0.1165, -0.1090]],\n",
       " \n",
       "         [[ 0.0201,  0.0167, -0.0118,  ..., -0.0531,  0.0098,  0.0423],\n",
       "          [ 0.0199,  0.0167, -0.0116,  ..., -0.0518,  0.0106,  0.0416],\n",
       "          [ 0.0202,  0.0166, -0.0111,  ..., -0.0509,  0.0117,  0.0409],\n",
       "          ...,\n",
       "          [ 0.0212,  0.0163, -0.0109,  ..., -0.0528,  0.0093,  0.0407],\n",
       "          [ 0.0194,  0.0169, -0.0116,  ..., -0.0536,  0.0094,  0.0417],\n",
       "          [ 0.0218,  0.0157, -0.0098,  ..., -0.0517,  0.0106,  0.0398]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.2.attention.heads.1.final_output': tensor([[[-0.0627,  0.2208,  0.0301,  ...,  0.0257,  0.0021,  0.0744],\n",
       "          [-0.0630,  0.2206,  0.0303,  ...,  0.0256,  0.0019,  0.0746],\n",
       "          [-0.0630,  0.2207,  0.0303,  ...,  0.0257,  0.0020,  0.0747],\n",
       "          ...,\n",
       "          [-0.0629,  0.2206,  0.0302,  ...,  0.0257,  0.0022,  0.0745],\n",
       "          [-0.0630,  0.2206,  0.0303,  ...,  0.0257,  0.0020,  0.0746],\n",
       "          [-0.0628,  0.2206,  0.0302,  ...,  0.0256,  0.0023,  0.0745]],\n",
       " \n",
       "         [[ 0.0056, -0.0018,  0.0047,  ...,  0.0385,  0.0138,  0.0024],\n",
       "          [ 0.0059, -0.0022,  0.0048,  ...,  0.0388,  0.0139,  0.0007],\n",
       "          [ 0.0056, -0.0016,  0.0047,  ...,  0.0389,  0.0143,  0.0012],\n",
       "          ...,\n",
       "          [ 0.0057, -0.0028,  0.0044,  ...,  0.0372,  0.0124,  0.0022],\n",
       "          [ 0.0060, -0.0023,  0.0049,  ...,  0.0386,  0.0136,  0.0012],\n",
       "          [ 0.0053, -0.0018,  0.0046,  ...,  0.0380,  0.0128,  0.0021]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.2.attention.heads.2.final_output': tensor([[[-1.4857e-01, -3.3896e-02, -1.6315e-01,  ...,  3.4942e-02,\n",
       "            7.0144e-02, -1.0372e-01],\n",
       "          [-1.4988e-01, -3.3583e-02, -1.6366e-01,  ...,  3.5366e-02,\n",
       "            6.9227e-02, -1.0344e-01],\n",
       "          [-1.4997e-01, -3.3489e-02, -1.6358e-01,  ...,  3.5378e-02,\n",
       "            6.9072e-02, -1.0344e-01],\n",
       "          ...,\n",
       "          [-1.4991e-01, -3.3425e-02, -1.6351e-01,  ...,  3.5197e-02,\n",
       "            6.9167e-02, -1.0341e-01],\n",
       "          [-1.4980e-01, -3.3454e-02, -1.6342e-01,  ...,  3.5154e-02,\n",
       "            6.9218e-02, -1.0341e-01],\n",
       "          [-1.4988e-01, -3.3259e-02, -1.6342e-01,  ...,  3.5273e-02,\n",
       "            6.9049e-02, -1.0328e-01]],\n",
       " \n",
       "         [[-2.3260e-03,  1.2535e-02, -3.2330e-03,  ...,  1.2704e-02,\n",
       "           -3.1515e-02, -3.4042e-04],\n",
       "          [-1.7030e-03,  1.2162e-02, -3.1233e-03,  ...,  1.2218e-02,\n",
       "           -3.0190e-02,  1.6184e-03],\n",
       "          [-1.3108e-03,  1.2426e-02, -2.9029e-03,  ...,  1.2324e-02,\n",
       "           -3.0373e-02,  1.6956e-03],\n",
       "          ...,\n",
       "          [-5.5763e-03,  1.1929e-02, -5.6287e-03,  ...,  1.2386e-02,\n",
       "           -3.0093e-02, -1.5379e-04],\n",
       "          [-5.1697e-03,  1.1912e-02, -5.3312e-03,  ...,  1.2331e-02,\n",
       "           -3.0261e-02,  9.2973e-05],\n",
       "          [-4.8765e-03,  1.1983e-02, -5.2359e-03,  ...,  1.2621e-02,\n",
       "           -3.0237e-02, -7.9742e-05]]], grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.2.attention.heads.3.final_output': tensor([[[ 0.0017,  0.0072, -0.0356,  ..., -0.0147,  0.0079, -0.0174],\n",
       "          [ 0.0138, -0.0389,  0.0021,  ..., -0.0008, -0.0021, -0.0088],\n",
       "          [ 0.0158, -0.0370, -0.0113,  ...,  0.0026, -0.0072, -0.0042],\n",
       "          ...,\n",
       "          [ 0.0227, -0.0520, -0.0038,  ...,  0.0208,  0.0074,  0.0044],\n",
       "          [ 0.0163, -0.0409,  0.0013,  ...,  0.0262,  0.0016, -0.0005],\n",
       "          [ 0.0039, -0.0468, -0.0118,  ...,  0.0171,  0.0051,  0.0182]],\n",
       " \n",
       "         [[-0.0047,  0.0267, -0.0349,  ..., -0.0341,  0.0110, -0.0243],\n",
       "          [-0.0035,  0.0353, -0.0205,  ...,  0.0087, -0.0091, -0.0242],\n",
       "          [-0.0217,  0.0364, -0.0083,  ...,  0.0283,  0.0166,  0.0074],\n",
       "          ...,\n",
       "          [ 0.0241, -0.0249, -0.0097,  ..., -0.0005, -0.0041, -0.0132],\n",
       "          [ 0.0317, -0.0120,  0.0352,  ...,  0.0026, -0.0113, -0.0004],\n",
       "          [-0.0046, -0.0028,  0.0280,  ..., -0.0031, -0.0057, -0.0003]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " 'encoder.blocks.3.mlp.final_output': tensor([[[-0.2569,  0.1213,  0.0111,  ...,  0.0214, -0.1192, -0.1253],\n",
       "          [-0.2559,  0.1205,  0.0109,  ...,  0.0209, -0.1186, -0.1248],\n",
       "          [-0.2559,  0.1205,  0.0109,  ...,  0.0208, -0.1186, -0.1248],\n",
       "          ...,\n",
       "          [-0.2559,  0.1205,  0.0108,  ...,  0.0207, -0.1186, -0.1248],\n",
       "          [-0.2556,  0.1203,  0.0109,  ...,  0.0208, -0.1185, -0.1247],\n",
       "          [-0.2561,  0.1207,  0.0109,  ...,  0.0211, -0.1188, -0.1248]],\n",
       " \n",
       "         [[ 0.0012, -0.0083, -0.0027,  ...,  0.0038,  0.0086,  0.0040],\n",
       "          [ 0.0064, -0.0127, -0.0045,  ...,  0.0045,  0.0105,  0.0066],\n",
       "          [ 0.0040, -0.0117, -0.0050,  ...,  0.0049,  0.0091,  0.0045],\n",
       "          ...,\n",
       "          [ 0.0057, -0.0119, -0.0037,  ...,  0.0035,  0.0107,  0.0068],\n",
       "          [ 0.0043, -0.0100, -0.0025,  ...,  0.0043,  0.0100,  0.0064],\n",
       "          [ 0.0036, -0.0101, -0.0029,  ...,  0.0040,  0.0097,  0.0056]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.3.attention.heads.0.final_output': tensor([[[-0.0424,  0.0094, -0.1484,  ..., -0.1035,  0.2377, -0.0908],\n",
       "          [-0.0424,  0.0094, -0.1484,  ..., -0.1039,  0.2382, -0.0906],\n",
       "          [-0.0423,  0.0094, -0.1483,  ..., -0.1038,  0.2380, -0.0906],\n",
       "          ...,\n",
       "          [-0.0426,  0.0096, -0.1486,  ..., -0.1037,  0.2381, -0.0908],\n",
       "          [-0.0426,  0.0097, -0.1488,  ..., -0.1039,  0.2379, -0.0908],\n",
       "          [-0.0427,  0.0098, -0.1486,  ..., -0.1037,  0.2380, -0.0909]],\n",
       " \n",
       "         [[-0.0222,  0.0178, -0.0307,  ..., -0.0008, -0.0085, -0.0093],\n",
       "          [-0.0223,  0.0176, -0.0295,  ...,  0.0005, -0.0117, -0.0085],\n",
       "          [-0.0222,  0.0176, -0.0289,  ...,  0.0010, -0.0130, -0.0080],\n",
       "          ...,\n",
       "          [-0.0224,  0.0176, -0.0305,  ..., -0.0004, -0.0084, -0.0088],\n",
       "          [-0.0224,  0.0169, -0.0290,  ...,  0.0007, -0.0104, -0.0077],\n",
       "          [-0.0223,  0.0172, -0.0291,  ...,  0.0004, -0.0104, -0.0076]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.3.attention.heads.1.final_output': tensor([[[ 0.0336,  0.1513,  0.1276,  ...,  0.0742, -0.0892, -0.0455],\n",
       "          [ 0.0333,  0.1511,  0.1277,  ...,  0.0743, -0.0890, -0.0455],\n",
       "          [ 0.0333,  0.1511,  0.1277,  ...,  0.0743, -0.0890, -0.0455],\n",
       "          ...,\n",
       "          [ 0.0338,  0.1511,  0.1277,  ...,  0.0743, -0.0888, -0.0455],\n",
       "          [ 0.0332,  0.1511,  0.1276,  ...,  0.0741, -0.0889, -0.0455],\n",
       "          [ 0.0336,  0.1513,  0.1277,  ...,  0.0744, -0.0892, -0.0457]],\n",
       " \n",
       "         [[-0.0185,  0.0037, -0.0216,  ..., -0.0009,  0.0157,  0.0016],\n",
       "          [-0.0192,  0.0041, -0.0215,  ..., -0.0010,  0.0157,  0.0011],\n",
       "          [-0.0192,  0.0046, -0.0214,  ..., -0.0009,  0.0152,  0.0013],\n",
       "          ...,\n",
       "          [-0.0184,  0.0031, -0.0216,  ..., -0.0009,  0.0167,  0.0010],\n",
       "          [-0.0179,  0.0027, -0.0221,  ..., -0.0016,  0.0167,  0.0019],\n",
       "          [-0.0177,  0.0030, -0.0217,  ..., -0.0012,  0.0165,  0.0018]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.3.attention.heads.2.final_output': tensor([[[-0.0180, -0.0390, -0.1154,  ..., -0.0671, -0.1790,  0.1873],\n",
       "          [-0.0183, -0.0398, -0.1155,  ..., -0.0671, -0.1789,  0.1876],\n",
       "          [-0.0183, -0.0399, -0.1155,  ..., -0.0670, -0.1789,  0.1876],\n",
       "          ...,\n",
       "          [-0.0180, -0.0401, -0.1158,  ..., -0.0674, -0.1789,  0.1875],\n",
       "          [-0.0181, -0.0395, -0.1159,  ..., -0.0674, -0.1788,  0.1871],\n",
       "          [-0.0181, -0.0398, -0.1158,  ..., -0.0673, -0.1787,  0.1873]],\n",
       " \n",
       "         [[ 0.0051, -0.0044,  0.0141,  ..., -0.0084,  0.0250, -0.0054],\n",
       "          [ 0.0043, -0.0031,  0.0159,  ..., -0.0067,  0.0274, -0.0085],\n",
       "          [ 0.0051, -0.0037,  0.0157,  ..., -0.0069,  0.0265, -0.0075],\n",
       "          ...,\n",
       "          [ 0.0043, -0.0044,  0.0124,  ..., -0.0089,  0.0238, -0.0037],\n",
       "          [ 0.0034, -0.0045,  0.0108,  ..., -0.0106,  0.0233, -0.0023],\n",
       "          [ 0.0038, -0.0047,  0.0123,  ..., -0.0097,  0.0244, -0.0038]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'encoder.blocks.3.attention.heads.3.final_output': tensor([[[-0.0191, -0.0254,  0.0153,  ..., -0.0435, -0.0116,  0.0149],\n",
       "          [ 0.0006,  0.0083,  0.0027,  ..., -0.0066,  0.0116, -0.0071],\n",
       "          [ 0.0055,  0.0083,  0.0018,  ..., -0.0128,  0.0206, -0.0071],\n",
       "          ...,\n",
       "          [-0.0193,  0.0152,  0.0285,  ...,  0.0087,  0.0059, -0.0043],\n",
       "          [-0.0028,  0.0051,  0.0293,  ...,  0.0279,  0.0013, -0.0113],\n",
       "          [-0.0157,  0.0107,  0.0291,  ..., -0.0217,  0.0191,  0.0018]],\n",
       " \n",
       "         [[-0.0200, -0.0272,  0.0088,  ..., -0.0460,  0.0174,  0.0141],\n",
       "          [ 0.0146,  0.0059, -0.0101,  ...,  0.0033, -0.0141, -0.0101],\n",
       "          [ 0.0150,  0.0103,  0.0110,  ...,  0.0019, -0.0068,  0.0048],\n",
       "          ...,\n",
       "          [ 0.0098, -0.0022, -0.0075,  ..., -0.0114,  0.0075, -0.0197],\n",
       "          [ 0.0023,  0.0155, -0.0021,  ...,  0.0015,  0.0024, -0.0136],\n",
       "          [-0.0148,  0.0104,  0.0036,  ..., -0.0081,  0.0129,  0.0100]]],\n",
       "        grad_fn=<ViewBackward0>)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(acdc)\n",
    "\n",
    "with acdc.SaveActivations(list(computation_graph.nodes.values())) as ctx:\n",
    "    vit(batch[0])\n",
    "    activations = ctx.get_activations()\n",
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading animal dataset from /home/lexyo/Dev/cv-proj2/notebooks/../data/animal_train.pkl\n",
      "Loading dataset from /home/lexyo/Dev/cv-proj2/notebooks/../data/valid.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>, 0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataset)\n",
    "animal_dataset, coarse_labels = dataset.load_animal_dataset(\"train\")\n",
    "animal_dataset[0]\n",
    "data = dataset.load(\"valid\", tiny=True)\n",
    "data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading animal dataset from /home/lexyo/Dev/cv-proj2/notebooks/../data/animal_train.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>, 0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataset)\n",
    "small_animal_dataset, coarse_labels = dataset.load_animal_dataset(\"train\", tiny=True, start=0, stop=4)\n",
    "# matching_dataset = dataset.ContrastiveWrapper(small_animal_dataset, coarse_labels)\n",
    "small_animal_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7F98D6545610>, 'label': 0}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Label label at index 1 not found in coarse_labels mapping.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmatching_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/cv-proj2/notebooks/../src/modules/dataset.py:242\u001b[39m, in \u001b[36mContrastiveWrapper.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    240\u001b[39m anchor_coarse_class = \u001b[38;5;28mself\u001b[39m.label_to_coarse_class.get(good_fine_label)\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m anchor_coarse_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLabel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgood_fine_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in coarse_labels mapping.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# 3. Get one \"bad\" sample (negative) from each of the other classes\u001b[39;00m\n\u001b[32m    245\u001b[39m bad_samples = []\n",
      "\u001b[31mValueError\u001b[39m: Label label at index 1 not found in coarse_labels mapping."
     ]
    }
   ],
   "source": [
    "matching_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(acdc)\n",
    "with acdc.ReplaceActivations(m.l2, activations[\"dense2\"]):\n",
    "    with acdc.SaveActivations([(m.l1, \"dense1\"), (m.l2, \"dense2\")]) as ctx:\n",
    "        print(m(torch.Tensor([1])))\n",
    "        activations1 = ctx.get_activations()\n",
    "    \n",
    "print(activations1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading animal dataset from /home/lexyo/Dev/cv-proj2/notebooks/../data/animal_train.pkl\n",
      "{0: 4, 1: 4, 2: 4, 3: 4, 4: 4, 5: 4, 6: 4, 7: 4, 8: 4, 9: 4, 10: 4, 11: 4, 12: 4, 13: 4, 14: 4, 15: 4, 16: 4, 17: 4, 18: 4, 19: 4, 20: 4, 21: 4, 22: 4, 23: 4, 24: 4, 25: 4, 26: 4, 27: 4, 28: 4, 29: 4, 30: 4, 31: 4, 32: 4, 33: 4, 34: 4, 35: 4, 36: 4, 37: 4, 38: 4, 39: 4, 40: 4, 41: 4, 42: 4, 43: 4, 44: 4, 45: 4, 46: 4, 47: 4, 48: 4, 49: 4, 50: 4, 51: 4, 52: 4, 53: 4, 170: 4, 184: 4, 187: 4, 190: 4}\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(dataset)\n",
    "small_animal_dataset, coarse_labels = dataset.load_animal_dataset(\"train\", tiny=True, start=0, stop=4)\n",
    "counting = {}\n",
    "for sample in small_animal_dataset:\n",
    "    if sample[\"label\"] not in counting: counting[sample[\"label\"]] = 1\n",
    "    else: counting[sample[\"label\"]]+=1\n",
    "print(counting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
